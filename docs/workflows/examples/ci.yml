# Continuous Integration Workflow for Secure MPC Transformer
# This file serves as a template - manual creation required due to GitHub App permissions

name: Continuous Integration

on:
  push:
    branches: [ main, develop, 'feature/**', 'bugfix/**' ]
  pull_request:
    branches: [ main, develop ]
    types: [opened, synchronize, reopened, ready_for_review]

# Cancel in-progress runs for the same PR/branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.10'
  NODE_VERSION: '18'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Pre-flight checks
  preflight:
    name: Pre-flight Checks
    runs-on: ubuntu-latest
    outputs:
      should-run-tests: ${{ steps.changes.outputs.src == 'true' || steps.changes.outputs.tests == 'true' }}
      should-build-docker: ${{ steps.changes.outputs.docker == 'true' || steps.changes.outputs.src == 'true' }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Check for changes
        uses: dorny/paths-filter@v2
        id: changes
        with:
          filters: |
            src:
              - 'src/**'
              - 'pyproject.toml'
              - 'requirements*.txt'
            tests:
              - 'tests/**'
            docker:
              - 'docker/**'
              - 'Dockerfile*'
            docs:
              - 'docs/**'
              - '*.md'

  # Security scanning
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    permissions:
      security-events: write
      contents: read
    steps:
      - uses: actions/checkout@v4
        
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          
      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
          
      - name: Run Bandit security scan
        run: |
          pip install bandit[toml]
          bandit -r src/ -f json -o bandit-report.json || true
          
      - name: Run Safety dependency scan
        run: |
          pip install safety
          safety check --json --output safety-report.json || true
          
      - name: Upload security reports
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json
            trivy-results.sarif

  # Code quality checks
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    needs: preflight
    if: needs.preflight.outputs.should-run-tests == 'true'
    steps:
      - uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
          
      - name: Run pre-commit hooks
        uses: pre-commit/action@v3.0.0
        
      - name: Run Black formatting check
        run: black --check --diff src/ tests/
        
      - name: Run isort import sorting check
        run: isort --check-only --diff src/ tests/ --profile black
        
      - name: Run Ruff linting
        run: ruff check src/ tests/ --output-format=github
        
      - name: Run MyPy type checking
        run: mypy src/ --ignore-missing-imports

  # Unit tests
  test-unit:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [preflight, quality]
    if: needs.preflight.outputs.should-run-tests == 'true'
    strategy:
      matrix:
        python-version: ['3.10', '3.11']
    steps:
      - uses: actions/checkout@v4
        
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,test]"
          
      - name: Run unit tests
        run: |
          python -m pytest tests/unit/ \
            -v \
            --cov=secure_mpc_transformer \
            --cov-report=xml \
            --cov-report=html \
            --cov-fail-under=80 \
            --junitxml=pytest-results.xml
            
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-${{ matrix.python-version }}
          path: |
            pytest-results.xml
            htmlcov/
            coverage.xml

  # Integration tests
  test-integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [preflight, test-unit]
    if: needs.preflight.outputs.should-run-tests == 'true'
    services:
      redis:
        image: redis:7.0-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,test]"
          
      - name: Run integration tests
        env:
          REDIS_URL: redis://localhost:6379
        run: |
          python -m pytest tests/integration/ \
            -v \
            --timeout=300 \
            --junitxml=integration-results.xml
            
      - name: Upload integration test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results
          path: integration-results.xml

  # GPU tests (self-hosted runner with GPU)
  test-gpu:
    name: GPU Tests
    runs-on: [self-hosted, gpu]
    needs: [preflight, test-unit]
    if: needs.preflight.outputs.should-run-tests == 'true'
    continue-on-error: true  # GPU tests are optional
    steps:
      - uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,test,gpu]"
          
      - name: Check GPU availability
        run: |
          nvidia-smi
          python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
          
      - name: Run GPU tests
        run: |
          python -m pytest tests/ --gpu -v \
            --timeout=600 \
            --junitxml=gpu-results.xml
            
      - name: Upload GPU test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: gpu-test-results
          path: gpu-results.xml

  # Build and test Docker images
  build-docker:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [preflight, security]
    if: needs.preflight.outputs.should-build-docker == 'true'
    permissions:
      contents: read
      packages: write
    strategy:
      matrix:
        target: [cpu, gpu, dev]
    steps:
      - uses: actions/checkout@v4
        
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch,suffix=-${{ matrix.target }}
            type=ref,event=pr,suffix=-${{ matrix.target }}
            type=sha,prefix={{branch}}-${{ matrix.target }}-
            
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile.${{ matrix.target }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64
          
      - name: Test Docker image
        run: |
          docker run --rm ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}-${{ matrix.target }} \
            python -c "import secure_mpc_transformer; print('Import successful')"

  # Performance benchmarks
  benchmark:
    name: Performance Benchmarks
    runs-on: [self-hosted, gpu]
    needs: [test-unit]
    if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,benchmark,gpu]"
          
      - name: Run benchmarks
        run: |
          python -m pytest tests/performance/ --benchmark \
            --benchmark-json=benchmark-results.json
            
      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: benchmark-results.json
          
      - name: Comment benchmark results on PR
        if: github.event_name == 'pull_request'
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'pytest'
          output-file-path: benchmark-results.json
          comment-on-alert: true
          github-token: ${{ secrets.GITHUB_TOKEN }}

  # Deployment readiness check
  deployment-check:
    name: Deployment Readiness
    runs-on: ubuntu-latest
    needs: [security, quality, test-unit, test-integration, build-docker]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
        
      - name: Check deployment prerequisites
        run: |
          echo "All CI checks passed - deployment ready"
          
      - name: Generate SBOM
        uses: anchore/sbom-action@v0
        with:
          path: ./
          format: spdx-json
          upload-artifact: true
          
      - name: Notify deployment system
        if: success()
        run: |
          # This would trigger deployment pipeline
          echo "Ready for deployment to staging environment"

  # Create release draft on main branch
  release-draft:
    name: Create Release Draft
    runs-on: ubuntu-latest
    needs: [deployment-check]
    if: github.ref == 'refs/heads/main' && success()
    permissions:
      contents: write
      pull-requests: read
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Create Release Draft
        uses: release-drafter/release-drafter@v5
        with:
          config-name: release-drafter.yml
          commitish: main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Cleanup
  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    needs: [security, quality, test-unit, test-integration, build-docker]
    if: always()
    steps:
      - name: Delete old artifacts
        uses: geekyeggo/delete-artifact@v2
        with:
          name: |
            security-reports
            test-results-*
            integration-test-results
            gpu-test-results
          failOnError: false